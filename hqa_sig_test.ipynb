{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\kaasa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import *\n",
    "from torchvision.utils import make_grid\n",
    "import numpy as np\n",
    "#from hqa_sig import *\n",
    "import pandas as pd\n",
    "from load_datasets import load_sig \n",
    "from torchsig.utils.dataset import SignalFileDataset\n",
    "from torchsig.datasets.modulations import ModulationsDataset\n",
    "import torchsig.transforms as ST\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.strategies.ddp import DDPStrategy\n",
    "from hqa_lightning_1D import HQA\n",
    "\n",
    "from scipy import interpolate\n",
    "from scipy import signal as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1234567891\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "#classes = [\"bpsk\",\"8pam\",\"8psk\",\"16qam\",\"16pam\",\"64qam\",\"64psk\",\"256qam\",\"1024qam\",\"16gmsk\"]\n",
    "classes = [\"4ask\",\"8pam\",\"16psk\",\"32qam_cross\",\"2fsk\",\"ofdm-256\"]\n",
    "num_classes = len(classes)\n",
    "training_samples_per_class = 4000\n",
    "valid_samples_per_class = 1000\n",
    "test_samples_per_class = 1000\n",
    "num_workers=15\n",
    "EPOCHS=1\n",
    "num_iq_samples = 4096\n",
    "layers = 5\n",
    "num_res_blocks = 2\n",
    "KL_coeff = 0.001\n",
    "CL_coeff = 0.001\n",
    "Cos_coeff = 0.001\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "\n",
    "\n",
    "data_transform = ST.Compose([\n",
    "    ST.Normalize(norm=np.inf),\n",
    "    ST.ComplexTo2D(),\n",
    "])\n",
    "\n",
    "pl.seed_everything(1234567891)\n",
    "\n",
    "ds_train = ModulationsDataset(\n",
    "    classes=classes,\n",
    "    use_class_idx=True,\n",
    "    level=0,\n",
    "    num_iq_samples=num_iq_samples,\n",
    "    num_samples=int(num_classes*training_samples_per_class),\n",
    "    include_snr=False,\n",
    "    transform = data_transform\n",
    ")\n",
    "\n",
    "ds_val = ModulationsDataset(\n",
    "    classes=classes,\n",
    "    use_class_idx=True,\n",
    "    level=0,\n",
    "    num_iq_samples=num_iq_samples,\n",
    "    num_samples=int(num_classes*valid_samples_per_class),\n",
    "    include_snr=False,\n",
    "    transform = data_transform\n",
    ")    \n",
    "\n",
    "ds_test = ModulationsDataset(\n",
    "    classes=classes,\n",
    "    use_class_idx=True,\n",
    "    level=0,\n",
    "    num_iq_samples=num_iq_samples,\n",
    "    num_samples=int(num_classes*test_samples_per_class),\n",
    "    include_snr=False,\n",
    "    transform = data_transform\n",
    ")\n",
    "\n",
    "dl_train = DataLoader(\n",
    "    dataset=ds_train,\n",
    "    batch_size=128,\n",
    "    #num_workers=num_workers,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "dl_val = DataLoader(\n",
    "    dataset=ds_val,\n",
    "    batch_size=128,\n",
    "    #num_workers=num_workers,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "dl_test = DataLoader(\n",
    "    dataset=ds_test,\n",
    "    batch_size=16,\n",
    "    #num_workers=num_workers,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "enc_hidden_sizes = [16, 16, 32, 64, 128]\n",
    "dec_hidden_sizes = [16, 64, 256, 512, 1024]\n",
    "model_save_path=os.path.join('Saved_models', f\"HQA_Sig_1D_iq{num_iq_samples}_{layers}layer_res{num_res_blocks}_KL{KL_coeff}_C{CL_coeff}_Classes6_e{EPOCHS}.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2, 4096]) tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([[ 6.2214e-01,  8.5672e-01,  7.0009e-01,  ..., -2.6651e-01,\n",
      "          2.8694e-01,  2.2426e-01],\n",
      "        [-3.5109e-06, -3.5503e-06,  1.4699e-06,  ...,  3.0515e-08,\n",
      "         -3.8939e-06,  1.4151e-06]])\n"
     ]
    }
   ],
   "source": [
    "inp,label = next(iter(dl_test)) \n",
    "print(inp.shape,label)\n",
    "print(inp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HQA(\n",
      "  (prev_model): HQA(\n",
      "    (prev_model): HQA(\n",
      "      (encoder): Encoder(\n",
      "        (blocks): Sequential(\n",
      "          (0): Conv1d(2, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "          (1): Mish()\n",
      "          (2): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (3): Mish()\n",
      "          (4): ResBlock(\n",
      "            (conv_1): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (conv_2): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (5): ResBlock(\n",
      "            (conv_1): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (conv_2): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (6): Conv1d(16, 256, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "      (codebook): VQCodebook(\n",
      "        (codebook): Embedding(256, 256)\n",
      "      )\n",
      "      (decoder): Decoder(\n",
      "        (blocks): Sequential(\n",
      "          (0): Conv1d(256, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (1): Mish()\n",
      "          (2): ResBlock(\n",
      "            (conv_1): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (conv_2): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (3): ResBlock(\n",
      "            (conv_1): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (conv_2): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "          (4): Upsample()\n",
      "          (5): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (6): Mish()\n",
      "          (7): Conv1d(8, 2, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (8): Tanh()\n",
      "        )\n",
      "      )\n",
      "      (normalize): GlobalNormalization1()\n",
      "    )\n",
      "    (encoder): Encoder(\n",
      "      (blocks): Sequential(\n",
      "        (0): Conv1d(256, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "        (1): Mish()\n",
      "        (2): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (3): Mish()\n",
      "        (4): ResBlock(\n",
      "          (conv_1): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (conv_2): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        )\n",
      "        (5): ResBlock(\n",
      "          (conv_1): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (conv_2): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        )\n",
      "        (6): Conv1d(16, 256, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (codebook): VQCodebook(\n",
      "      (codebook): Embedding(256, 256)\n",
      "    )\n",
      "    (decoder): Decoder(\n",
      "      (blocks): Sequential(\n",
      "        (0): Conv1d(256, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (1): Mish()\n",
      "        (2): ResBlock(\n",
      "          (conv_1): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (conv_2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        )\n",
      "        (3): ResBlock(\n",
      "          (conv_1): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (conv_2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        )\n",
      "        (4): Upsample()\n",
      "        (5): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (6): Mish()\n",
      "        (7): Conv1d(32, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      )\n",
      "    )\n",
      "    (normalize): GlobalNormalization1()\n",
      "  )\n",
      "  (encoder): Encoder(\n",
      "    (blocks): Sequential(\n",
      "      (0): Conv1d(256, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "      (1): Mish()\n",
      "      (2): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (3): Mish()\n",
      "      (4): ResBlock(\n",
      "        (conv_1): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (conv_2): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      )\n",
      "      (5): ResBlock(\n",
      "        (conv_1): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (conv_2): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      )\n",
      "      (6): Conv1d(32, 256, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (codebook): VQCodebook(\n",
      "    (codebook): Embedding(256, 256)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (blocks): Sequential(\n",
      "      (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (1): Mish()\n",
      "      (2): ResBlock(\n",
      "        (conv_1): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (conv_2): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      )\n",
      "      (3): ResBlock(\n",
      "        (conv_1): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (conv_2): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      )\n",
      "      (4): Upsample()\n",
      "      (5): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (6): Mish()\n",
      "      (7): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    )\n",
      "  )\n",
      "  (normalize): GlobalNormalization1()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "hqa_model = torch.load(model_save_path)\n",
    "\n",
    "print(hqa_model[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(layers): #changed from five for  faster evaluation\n",
    "    hqa=hqa_model[i]\n",
    "    test_x, lab = next(iter(dl_test))\n",
    "    hqa.eval()\n",
    "    test_y = hqa.reconstruct(test_x)\n",
    "    test_y = test_y.detach().cpu().numpy()\n",
    "    batch_size= test_y.shape[0]\n",
    "    figure1 = plt.figure()\n",
    "    for k in range(batch_size):\n",
    "        test_xiq = test_x.detach().cpu().numpy()[k,:,:]\n",
    "        x=test_xiq[0,:]+ 1j*test_xiq[1,:]\n",
    "        plt.subplot(\n",
    "            int(np.ceil(np.sqrt(batch_size))),\n",
    "            int(np.sqrt(batch_size)),\n",
    "            k+1,\n",
    "        )\n",
    "        _, _, spectrogram = sp.spectrogram(\n",
    "            x=x,\n",
    "            fs=1.0,\n",
    "            window=sp.windows.tukey(1024, 0.25),\n",
    "            nperseg=1024,\n",
    "            return_onesided=False,\n",
    "            nfft=4096\n",
    "        )\n",
    "        spectrogram = 20 * np.log10(np.fft.fftshift(np.abs(spectrogram) + np.finfo(float).eps, axes=0))\n",
    "        plt.imshow(\n",
    "            spectrogram,\n",
    "            vmin=np.min(spectrogram[spectrogram != -np.inf]),\n",
    "            vmax=np.max(spectrogram[spectrogram != np.inf]),\n",
    "            aspect=\"auto\",\n",
    "            cmap=\"jet\",\n",
    "        )\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(str(lab[k]))\n",
    "    figure1.savefig(f'Visuals/spectr2oKL{i}{k}_e{EPOCHS}.png')            \n",
    "    figure2 = plt.figure(2)    \n",
    "    for k in range(batch_size):\n",
    "        test_yiq=test_y[k,:,:]\n",
    "        x_hat=test_yiq[0,:]+ 1j*test_yiq[1,:]\n",
    "        plt.subplot(\n",
    "            int(np.ceil(np.sqrt(batch_size))),\n",
    "            int(np.sqrt(batch_size)),\n",
    "            k+1,\n",
    "        )\n",
    "        _, _, spectrogram = sp.spectrogram(\n",
    "            x=x_hat,\n",
    "            fs=1.0,\n",
    "            window=sp.windows.tukey(1024, 0.25),\n",
    "            nperseg=1024,\n",
    "            return_onesided=False,\n",
    "            nfft=4096\n",
    "        )\n",
    "        spectrogram = 20 * np.log10(np.fft.fftshift(np.abs(spectrogram) + np.finfo(float).eps, axes=0))\n",
    "        plt.imshow(\n",
    "            spectrogram,\n",
    "            vmin=np.min(spectrogram[spectrogram != -np.inf]),\n",
    "            vmax=np.max(spectrogram[spectrogram != np.inf]),\n",
    "            aspect=\"auto\",\n",
    "            cmap=\"jet\",\n",
    "        )\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(str(lab[k]))\n",
    "    figure2.savefig(f'Visuals/spectr2oKL_hat{i}{k}_e{EPOCHS}.png')\n",
    "    figure3 = plt.figure(3) \n",
    "    for k in range(batch_size):\n",
    "        test_xiq = test_x.detach().cpu().numpy()[k,:,:]\n",
    "        x=test_xiq[0,:]+ 1j*test_xiq[1,:]\n",
    "        plt.subplot(\n",
    "            int(np.ceil(np.sqrt(batch_size))),\n",
    "            int(np.sqrt(batch_size)),\n",
    "            k+1,\n",
    "        )\n",
    "        plt.plot(np.real(x))\n",
    "        plt.plot(np.imag(x))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(str(lab[k]))\n",
    "    figure3.savefig(f'Visuals/iq2oKL{i}{k}_e{EPOCHS}.png')\n",
    "    figure4 = plt.figure(4) \n",
    "    for k in range(batch_size):\n",
    "        test_yiq=test_y[k,:,:]\n",
    "        x_hat=test_yiq[0,:]+ 1j*test_yiq[1,:]\n",
    "        plt.subplot(\n",
    "            int(np.ceil(np.sqrt(batch_size))),\n",
    "            int(np.sqrt(batch_size)),\n",
    "            k+1,\n",
    "        )\n",
    "        plt.plot(np.real(x_hat))\n",
    "        plt.plot(np.imag(x_hat))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(str(lab[k]))\n",
    "    figure4.savefig(f'Visuals/iq2oKL_hat{i}{k}_e{EPOCHS}.png')\n",
    "plt.close('all')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
